"use strict";
var __importDefault = (this && this.__importDefault) || function (mod) {
    return (mod && mod.__esModule) ? mod : { "default": mod };
};
Object.defineProperty(exports, "__esModule", { value: true });
const stream_1 = require("stream");
const fs_1 = require("fs");
const util_1 = require("util");
const os_1 = require("os");
const path_1 = require("path");
const nanoid_1 = require("nanoid");
const formdata_node_1 = require("formdata-node");
const BodyFileDataItem_1 = require("../BodyFileDataItem");
const getFieldPath_1 = __importDefault(require("../util/getFieldPath"));
const requestEntityTooLarge_1 = __importDefault(require("../util/requestEntityTooLarge"));
const pipe = util_1.promisify(stream_1.pipeline);
const createOnFile = ({ limits }, entries) => (fieldname, stream, filename, enc, mime) => {
    const path = path_1.join(os_1.tmpdir(), `${nanoid_1.nanoid()}__${filename}`);
    const dest = fs_1.createWriteStream(path);
    entries.enqueue();
    async function onFulfilled() {
        const fieldPath = getFieldPath_1.default(fieldname);
        const file = await formdata_node_1.fileFromPath(path, filename, { type: mime });
        entries.pull([fieldPath, new BodyFileDataItem_1.BodyFileDataItem({ file, path, enc })]);
    }
    function onLimit() {
        stream.unpipe();
        entries.emit("error", requestEntityTooLarge_1.default(`File size limit exceeded: Available up to ${limits.fileSize} bytes per file.`));
    }
    function onRejected(error) {
        stream.unpipe();
        entries.emit("error", error);
    }
    // Hope this will work when using with pipeline
    stream.on("limit", onLimit);
    pipe(stream, dest).then(onFulfilled).catch(onRejected);
};
exports.default = createOnFile;
